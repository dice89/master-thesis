// Class with some static WordNet helper functionspackage de.unima.dws.oamatching.util.wordnet;import java.io.BufferedReader;import java.io.ByteArrayInputStream;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileReader;import java.io.IOException;import java.util.ArrayList;import java.util.HashMap;import java.util.HashSet;import java.util.Iterator;import java.util.List;import java.util.Map;import java.util.Set;import net.didion.jwnl.JWNL;import net.didion.jwnl.JWNLException;import net.didion.jwnl.data.IndexWord;import net.didion.jwnl.data.POS;import net.didion.jwnl.data.PointerUtils;import net.didion.jwnl.data.Synset;import net.didion.jwnl.data.Word;import net.didion.jwnl.data.list.PointerTargetNode;import net.didion.jwnl.data.list.PointerTargetNodeList;import net.didion.jwnl.data.list.PointerTargetTree;import net.didion.jwnl.dictionary.Dictionary;import net.didion.jwnl.dictionary.FileBackedDictionary;import net.didion.jwnl.dictionary.MapBackedDictionary;import net.didion.jwnl.dictionary.MorphologicalProcessor;import de.unima.dws.oamatching.config.Config;import de.unima.dws.oamatching.datatypes.wn.LCS;import de.unima.dws.oamatching.datatypes.wn.OffsetPair;import de.unima.dws.oamatching.datatypes.wn.WNOffset;import de.unima.dws.oamatching.util.LabelTokenizer;/** * Original Code from YAM ++ *  * @author modified by (Alexander C. Mueller) *  */public class WordNetHelper {	// using singleton pattern	private static WordNetHelper instance = null;	// Dictionary object	private FileBackedDictionary dictionary;	// internal cache	// private Map<OffsetPair, LCS> cache;	// private LRUCache<OffsetPair, LCS> cache;	// wordnet wnStemmer	public WordNetStemmer wnstemmer;	// initial status	public boolean alreadySetDict = false;	public boolean alreadySetIC = false;	/**	 * This map stores the synset IDs and there associated frequencies as read	 * from the supplied information content file.	 */	private Map<String, Double> freq;	// /////////////////////////////////////////////////////////////////////////////////	private WordNetHelper() {		// cache = new HashMap<OffsetPair, LCS>();		// cache = new LRUCache<OffsetPair, LCS>(100000);		freq = new HashMap<String, Double>();	}	public static WordNetHelper getInstance() throws Exception {		if (instance == null){			instance = new WordNetHelper();			instance.initializeWN(Config.WNDIR(), Config.WNVER());			instance.initializeIC(Config.WNIC());		}				//add init code		return instance;	}	public Dictionary getDictionary() {		return dictionary;	}	// //////////////////////////////////////////////////////////////////////////////////	// Initialize the database!	public void initializeWN(String propsFile) {		if (alreadySetDict)			return;		// String propsFile = "file_properties.xml";		try {			JWNL.initialize(new FileInputStream(propsFile));		} catch (FileNotFoundException e) {			e.printStackTrace();		} catch (JWNLException e) {			e.printStackTrace();		}		// Create dictionary object		dictionary = (FileBackedDictionary) FileBackedDictionary.getInstance();		wnstemmer = new WordNetStemmer(dictionary);		alreadySetDict = true;	}	public void initializeWN(String wordnetdir, String wordnetversion)			throws Exception {		// to avoid multiple initializing the same dcitionary		// Supports.createWNPropertyFile(wordnetdir, wordnetversion);		// initialize wordnet		// initializeWN(Configs.WNPROP);		// System.out.println("New method of initializing WN");		if (alreadySetDict)			return;		String props = Supports.createWNPropertyString(wordnetdir,				wordnetversion);		JWNL.initialize(new ByteArrayInputStream(props.getBytes("UTF-8")));		// Create dictionary object				dictionary = (FileBackedDictionary) Dictionary.getInstance();		wnstemmer = new WordNetStemmer(dictionary);		alreadySetDict = true;	}	public void uninstall() {		dictionary.uninstall();		JWNL.shutdown();		freq.clear();		alreadySetDict = false;		alreadySetIC = false;	}	public WordNetStemmer getWnstemmer() {		return wnstemmer;	}	// //////////////////////////////////////////////////////////////////////////////////////////	// get synset from offset and POS	public Synset getSynset(POS pos, long offset) {		try {			return dictionary.getSynsetAt(pos, offset);		} catch (JWNLException e) {					e.printStackTrace();		}		return null;	}	// get list of lema without sense number	public String getLemas(Synset synset) {		StringBuffer buf = new StringBuffer();		for (Word word : synset.getWords()) {			buf.append(word.getLemma());			buf.append(" ");		}		return buf.toString().trim();	}	// convert PointerTargetNodeList into list of synsets	public List<Synset> flatSynsets(PointerTargetNodeList nodelist) {		List<Synset> synsets = new ArrayList<Synset>();		Iterator<PointerTargetNode> it = nodelist.iterator();		while (it.hasNext()) {			PointerTargetNode pointerTargetNode = it.next();			synsets.add(pointerTargetNode.getSynset());		}		return synsets;	}	// convert PointerTargetTree into list of list of synsets	public List<List<Synset>> hierarchySynsets(PointerTargetTree tree) {		List<List<Synset>> lists = new ArrayList<List<Synset>>();		List<PointerTargetNodeList> nodelists = tree.toList();		for (PointerTargetNodeList nodelist : nodelists) {			List<Synset> synsets = new ArrayList<Synset>();			for (int i = 0; i < nodelist.size(); i++) {				synsets.add(((PointerTargetNode) nodelist.get(i)).getSynset());			}			lists.add(synsets);		}		return lists;	}	// convert PointerTargetTree into list of list of synsets	public List<Synset> flatSynsets(PointerTargetTree tree) {		List<Synset> lists = new ArrayList<Synset>();		List<PointerTargetNodeList> nodelists = tree.toList();		for (PointerTargetNodeList nodelist : nodelists) {			List<Synset> synsets = new ArrayList<Synset>();			for (int i = 0; i < nodelist.size(); i++) {				synsets.add(((PointerTargetNode) nodelist.get(i)).getSynset());			}			lists.addAll(synsets);		}		return lists;	}	// Get the IndexWord object for a String and POS	public IndexWord getSimpleIndexWord(POS pos, String s) throws JWNLException {		IndexWord indexword = dictionary.getIndexWord(pos, s);		return indexword;	}	public IndexWord getFullIndexWord(POS pos, String s) throws JWNLException {		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			IndexWord indexword = dictionary.getIndexWord(pos, s);			return indexword;		}		// if morphologicalProcesor is set up		return morphing.lookupBaseForm(pos, s);	}	// get all synsets form of word with specific POS	public List<Synset> getAllSynsets(POS pos, String lema)			throws JWNLException {		List<Synset> list = new ArrayList<Synset>();		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			return list;		}		IndexWord indexword = morphing.lookupBaseForm((POS) pos, lema);		if (indexword != null) {			for (Synset synset : indexword.getSenses()) {				list.add(synset);			}		}		return list;	}	// get all synsets form of word	// they are including all morphological forms of current word	public List<Synset> getAllSynsets(String lema) throws JWNLException {		List<Synset> list = new ArrayList<Synset>();		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			return list;		}		for (Object pos : POS.getAllPOS()) {			IndexWord indexword = morphing.lookupBaseForm((POS) pos, lema);			if (indexword != null) {				for (Synset synset : indexword.getSenses()) {					list.add(synset);				}			}		}		return list;	}	public List<Synset> getAllSynsetsWithoutMorphing(String lema)			throws JWNLException {		List<Synset> list = new ArrayList<Synset>();		for (Object pos : POS.getAllPOS()) {			IndexWord indexword = dictionary.lookupIndexWord((POS) pos, lema);			if (indexword != null) {				for (Synset synset : indexword.getSenses()) {					list.add(synset);				}			}		}		return list;	}	// depth : maximum sense index of lema	// e.g: if depth = 3,lema = man --> list only: man#1, man#2, man#3	public List<Synset> getLimitSynsetsByPOS(POS pos, String lema, int depth)			throws JWNLException {		List<Synset> list = new ArrayList<Synset>();		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			return list;		}		// get all available bases of lema with specific pos		List<String> bases = morphing.lookupAllBaseForms(pos, lema);		// List<String> bases = getMaxBaseForm(lema, pos);		for (String base : bases) {			// get all senses of this word			IndexWord indexword = dictionary.lookupIndexWord(pos, base);			if (indexword != null) {				Synset[] synsets = indexword.getSenses();				if (depth > synsets.length)					depth = synsets.length;				// access to all synset				for (int i = 0; i < depth; i++) {					Synset synset = synsets[i];					/*					 * if (Configs.DEBUG) { System.out.println("synset : " +					 * synset.getOffset() + " sense's index : " + (i + 1));					 * 					 * int usageCount = dictionary.getUsageCount(					 * synset.getOffset(), base);					 * 					 * System.out.println("Usage count = " + usageCount); }					 */					list.add(synset);				}			}		}		return list;	}	public List<Synset> getLimitSynsetsByPOSWithoutMorphing(POS pos,			String lema, int depth) throws JWNLException {		List<Synset> list = new ArrayList<Synset>();		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			return list;		}		// IndexWord indexword = dictionary.lookupIndexWord(pos, lema);		IndexWord indexword = morphing.lookupBaseForm(pos, lema);		/*		 * if(lema.equals("subject area") || lema.equals("topic")) {		 * 		 * System.out.println(indexword); if(indexword != null) { for(long syn :		 * indexword.getSynsetOffsets()) System.out.print(syn + "\t"); }		 * System.out.println();		 * System.out.println("------------- -----------------------"); }		 */		if (indexword != null) {			Synset[] synsets = indexword.getSenses();			if (depth > synsets.length)				depth = synsets.length;			// access to all synset			for (int i = 0; i < depth; i++) {				Synset synset = synsets[i];				/*				 * if (Configs.DEBUG) { System.out.println("synset : " +				 * synset.getOffset() + " sense's index : " + (i + 1));				 * 				 * int usageCount = dictionary.getUsageCount(synset.getOffset(),				 * lema);				 * 				 * System.out.println("Usage count = " + usageCount); }				 */				list.add(synset);			}		}		return list;	}	public List<String> getAllBaseForm(String word, POS pos)			throws JWNLException {		List<String> bases = new ArrayList<String>();		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			return bases;		}		// get all available bases of lema with specific pos		@SuppressWarnings("unchecked")		List<String> founds = morphing.lookupAllBaseForms(pos, word);		for (String item : founds)			bases.add(item);		return bases;	}	public List<String> getMaxBaseForm(String word, POS pos)			throws JWNLException {		List<String> bases = new ArrayList<String>();		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			return bases;		}		// get all available bases of lema with specific pos		List<String> founds = morphing.lookupAllBaseForms(pos, word);		int maxlen = 0;		for (String item : founds) {			if (item.length() > maxlen)				maxlen = item.length();		}		for (String item : founds) {			if (item.length() == maxlen)				bases.add(item + " : " + pos.toString());		}		return bases;	}	public Set<String> getAllBaseForm(String word, int minLength)			throws JWNLException {		Set<String> bases = new HashSet<String>();		for (Object pos : POS.getAllPOS()) {			for (String item : getAllBaseForm(word, (POS) pos)) {				if (item.length() >= minLength)					bases.add(item);			}		}		return bases;	}	public Set<String> getAllBaseForm(String word, POS pos, int minLength)			throws JWNLException {		Set<String> bases = new HashSet<String>();		for (String item : getAllBaseForm(word, (POS) pos)) {			if (item.length() >= minLength)				bases.add(item);		}		return bases;	}	public Set<String> getMaxBaseForm(String word, int minLength)			throws JWNLException {		Set<String> bases = new HashSet<String>();		for (Object pos : POS.getAllPOS()) {			for (String item : getMaxBaseForm(word, (POS) pos)) {				if (item.length() >= minLength)					bases.add(item);			}		}		return bases;	}	// list all synset and total usage count of lema in dictionary	public int getAllSynsetsWithTotalUsageCount(POS pos, String lema,			int depth, List<Synset> list) throws JWNLException {		// total usage count of lema in pos and with restricted depth		int total = 0;		MorphologicalProcessor morphing = dictionary				.getMorphologicalProcessor();		if (morphing == null) {			System.out.println("error in getting morphological processor");			return 0;		}		// get all available bases of lema with specific pos		List<String> bases = morphing.lookupAllBaseForms(pos, lema);		for (String base : bases) {			// get all senses of this word			IndexWord indexword = dictionary.lookupIndexWord(pos, base);			if (indexword != null) {				Synset[] synsets = indexword.getSenses();				if (depth > synsets.length)					depth = synsets.length;				// access to all synset				for (int i = 0; i < depth; i++) {					Synset synset = synsets[i];					int usagecount = 0;					//dictionary.getUsageCount(							//synset.getOffset(), base);					total += usagecount;					/*					 * if (Configs.DEBUG) { System.out.println("synset : " +					 * synset.getOffset() + " sense's index : " + (i + 1));					 * System.out.println("Usage count = " + usagecount); }					 */					list.add(synset);				}			}		}		return total;	}	public List<Synset> getAllSynsets(String lema, int depth)			throws JWNLException {		List<Synset> list = new ArrayList<Synset>();		for (Object item : POS.getAllPOS()) {			POS pos = (POS) item;			list.addAll(getLimitSynsetsByPOS(pos, lema, depth));		}		return list;	}	public Set<Synset> getRelatedNounSynset(String word) throws JWNLException {		Set<Synset> senses = new HashSet<Synset>();		for (Synset synset : getAllSynsets(POS.ADJECTIVE, word)) {			PointerTargetNodeList list = PointerUtils.getInstance().getDerived(					synset);			for (int i = 0; i < list.size(); i++) {				senses.add(((PointerTargetNode) list.get(i)).getSynset());			}		}		return senses;	}	// ///////////////////////////////////////////////////////////////////////////	public WNOffset getCommonSynset(PointerTargetNodeList list1,			PointerTargetNodeList list2) {		int cc = 0;		int i = 1;		while (i <= Math.min(list1.size(), list2.size())) {			Synset syn1 = ((PointerTargetNode) list1.get(list1.size() - i))					.getSynset();			Synset syn2 = ((PointerTargetNode) list2.get(list2.size() - i))					.getSynset();			if (syn1.getOffset() == syn2.getOffset()) {				cc++;				i++;			} else				break;		}		if (cc > 0) {			i--;			Synset syn = ((PointerTargetNode) list1.get(list1.size() - i))					.getSynset();			return new WNOffset(syn.getOffset(), cc);		}		return null;	}	public LCS getLCS(Synset synset1, Synset synset2) throws JWNLException {		// if synsets are the same		if (synset1 == synset2) {			long offset = synset1.getOffset();			return new LCS(offset, 100, offset, 100, offset, 100);			// return new LCS(offset, 1, offset, 1, offset, 1);		}		// if existing in cache, then get it		OffsetPair pair = new OffsetPair(synset1.getOffset(),				synset2.getOffset());		/*		 * if (cache.contain(pair)) { if (Configs.DEBUG)		 * System.out.println("WordNetHelper: Found on cahce : " +		 * pair.toString()); return cache.get(pair); }		 */		List<PointerTargetNodeList> lists1 = PointerUtils.getInstance()				.getHypernymTree(synset1).toList();		List<PointerTargetNodeList> lists2 = PointerUtils.getInstance()				.getHypernymTree(synset2).toList();		WNOffset lcs = null;		int depth = 0;		int depth1 = 0;		int depth2 = 0;		/*		 * if(Configs.BREAKPOINT) { System.out.println("Synset information : " +		 * synset1.getOffset() + "\t" + synset2.getOffset());		 * 		 * System.out.println("WordNetHelper : lists synsets size : " +		 * lists1.size() + "\t" + lists2.size());		 * 		 * }		 */		for (PointerTargetNodeList list1 : lists1) {			/*			 * if(Configs.BREAKPOINT) {			 * System.out.print("WordNetHelper List 1 \t : "); for(int i = 0; i			 * < list1.size(); i++) { PointerTargetNode node =			 * (PointerTargetNode) list1.get(i);			 * System.out.print(node.getSynset().getOffset() + "\t"); }			 * 			 * System.out.println(); }			 */			for (PointerTargetNodeList list2 : lists2) {				/*				 * if(Configs.BREAKPOINT) {				 * System.out.print("WordNetHelper List 2 \t : "); for(int i =				 * 0; i < list2.size(); i++) { PointerTargetNode node =				 * (PointerTargetNode) list2.get(i);				 * System.out.print(node.getSynset().getOffset() + "\t"); }				 * 				 * System.out.println(); }				 */				WNOffset common = getCommonSynset(list1, list2);				/*				 * if(Configs.BREAKPOINT && common != null) {				 * System.out.println("WordNetHelper : common = " +				 * common.toString()); }				 */				if (common != null) {					if (common.getDepth() > depth) {						depth = common.getDepth();						depth1 = list1.size();						depth2 = list2.size();						lcs = common;					}					/*					 * if(Configs.BREAKPOINT) {					 * System.out.println("WordNetHelper : LCS = " +					 * lcs.toString()); System.out.println(					 * "----------------------------------------------------------\n"					 * ); }					 */				}			}		}		// if lowest common synset exists		if (lcs != null) {			// create a new LCS			LCS res = new LCS(lcs.getOffset(), lcs.getDepth(),					synset1.getOffset(), depth1, synset2.getOffset(), depth2);			// save in cache			// cache.put(pair, res);			return res;		}		// cache.put(pair, null);		return null;	}	// finding lowest common synset between 2 list of synsets	public LCS getLCS(List<Synset> list1, List<Synset> list2)			throws JWNLException {		int depth = 0;		LCS lcs = null;		// if one of 2 indexes = null --> return null		if (list1.size() != 0 && list2.size() != 0) {			for (Synset syn1 : list1) {				for (Synset syn2 : list2) {					LCS common = getLCS(syn1, syn2);					if (common != null) {						if (common.getDepth() > depth) {							depth = common.getDepth();							lcs = common;						}					}				}			}		}		return lcs;	}	// finding lowest common synset between 2 index words	public LCS getLCS(IndexWord index1, IndexWord index2) throws JWNLException {		int depth = 0;		LCS lcs = null;		// if one of 2 indexes = null --> return null		if (index1 != null && index2 != null) {			for (Synset syn1 : index1.getSenses()) {				for (Synset syn2 : index2.getSenses()) {					LCS common = getLCS(syn1, syn2);					if (common != null) {						if (common.getDepth() > depth) {							depth = common.getDepth();							lcs = common;						}					}				}			}		}		return lcs;	}	// finding lowest common synset between 2 words with specific POS	public LCS getLCS(POS pos, String word1, String word2) throws JWNLException {		IndexWord indexword1 = getFullIndexWord(pos, word1);		IndexWord indexword2 = getFullIndexWord(pos, word2);		return getLCS(indexword1, indexword2);	}	public LCS getLCS(POS pos, String word1, String word2, int depth)			throws JWNLException {		List<Synset> list1 = getLimitSynsetsByPOS(pos, word1, depth);		List<Synset> list2 = getLimitSynsetsByPOS(pos, word2, depth);		return getLCS(list1, list2);	}	// This method is used for computing sim.score between Adjective and Adverb	// Noun and Verb synsets usually do not have synonym synsets	public float getSynonymScore(IndexWord index1, IndexWord index2) {		// the max number of common concepts between the two tokens		double value = 0;		if (index1 != null && index2 != null) {			// The two tokens existe in WordNet, we find the "depth"			try {				// Synsets for each token				Synset[] Syno1 = index1.getSenses();				Synset[] Syno2 = index2.getSenses();				for (int i = 0; i < index1.getSenseCount(); i++) {					// get synset of first word					Synset synset1 = Syno1[i];					for (int k = 0; k < index2.getSenseCount(); k++) {						// get synset of second word						Synset synset2 = Syno2[k];						if (synset1.equals(synset2))							return 1;						PointerTargetNodeList synList = PointerUtils								.getInstance().getSynonyms(synset1);						Iterator listIt = synList.iterator();						// browse lists						while (listIt.hasNext()) {							PointerTargetNode ptn = (PointerTargetNode) listIt									.next();							// if one synset exists in set of synonym synsets of							// the other							if (ptn.getSynset().equals(synset2)) {								value = 1;							}						}					}				}				// System.err.println("value = " + value);				return (float) value;			} catch (JWNLException je) {				je.printStackTrace();			}		}		return Config.UN_KNOWN();	}	public float getSynonymScore(List<Synset> list1, List<Synset> list2) {		// the max number of common concepts between the two tokens		double value = 0;		if (list1.size() != 0 && list2.size() != 0) {			// The two tokens existe in WordNet, we find the "depth"			try {				for (Synset synset1 : list1) {					for (Synset synset2 : list2) {						if (synset1.equals(synset2))							return 1;						PointerTargetNodeList synList = PointerUtils								.getInstance().getSynonyms(synset1);						Iterator listIt = synList.iterator();						// browse lists						while (listIt.hasNext()) {							PointerTargetNode ptn = (PointerTargetNode) listIt									.next();							// if one synset exists in set of synonym synsets of							// the other							if (ptn.getSynset().equals(synset2)) {								value = 1;							}						}					}				}				// System.err.println("value = " + value);				return (float) value;			} catch (JWNLException je) {				je.printStackTrace();			}		}		return Config.UN_KNOWN();	}	public int getSubSuperScore(Synset synset1, Synset synset2)			throws JWNLException {		List<PointerTargetNodeList> lists1 = PointerUtils.getInstance()				.getHypernymTree(synset1).toList();		List<PointerTargetNodeList> lists2 = PointerUtils.getInstance()				.getHypernymTree(synset2).toList();		for (PointerTargetNodeList list1 : lists1) {			for (PointerTargetNodeList list2 : lists2) {				WNOffset common = getCommonSynset(list1, list2);				if (common != null) {					int depth = common.getDepth();					int depth1 = list1.size();					int depth2 = list2.size();					// return 0 if they are synonym					// return positive if synset1 is super synset of synset2					// return negative if synset1 is sub synset of synset2					if (depth == depth1 || depth == depth2) {						return depth2 - depth1;					} else {						return Config.NOT_IS_A();					}				}			}		}		return Config.NOT_IS_A();	}	public int getSubSuperScore(String word1, String word2)			throws JWNLException {		String word1stem = wnstemmer.Stem(word1);		String word2stem = wnstemmer.Stem(word2);		IndexWord indexword1 = dictionary.lookupIndexWord(POS.NOUN, word1stem);		IndexWord indexword2 = dictionary.lookupIndexWord(POS.NOUN, word2stem);		int mindistance = Config.NOT_IS_A();		if (indexword1 == null || indexword2 == null)			return mindistance;		for (Synset synset1 : indexword1.getSenses()) {			for (Synset synset2 : indexword2.getSenses()) {				int distance = getSubSuperScore(synset1, synset2);				if (distance < mindistance)					mindistance = distance;			}		}		return mindistance;	}	public double getSubSuperICScore(Synset synset1, Synset synset2)			throws JWNLException {		List<PointerTargetNodeList> lists1 = PointerUtils.getInstance()				.getHypernymTree(synset1).toList();		List<PointerTargetNodeList> lists2 = PointerUtils.getInstance()				.getHypernymTree(synset2).toList();		for (PointerTargetNodeList list1 : lists1) {			for (PointerTargetNodeList list2 : lists2) {				WNOffset common = getCommonSynset(list1, list2);				if (common != null) {					int depth = common.getDepth();					int depth1 = list1.size();					int depth2 = list2.size();					double synset1IC = getIC(synset1);					double synset2IC = getIC(synset2);					// return 0 if they are synonym					// return positive if synset1 is super synset of synset2					// return negative if synset1 is sub synset of synset2					if (depth == depth1) {						return 2 * synset1IC / (synset1IC + synset2IC);					} else if (depth == depth2) {						return 2 * synset2IC / (synset1IC + synset2IC);					}				}			}		}		return Config.NOT_IS_A();	}	public double getSubSuperICScore(String word1, String word2)			throws JWNLException {		String word1stem = wnstemmer.Stem(word1);		String word2stem = wnstemmer.Stem(word2);		IndexWord indexword1 = dictionary.lookupIndexWord(POS.NOUN, word1stem);		IndexWord indexword2 = dictionary.lookupIndexWord(POS.NOUN, word2stem);		double mindistance = Config.NOT_IS_A();		if (indexword1 == null || indexword2 == null)			return mindistance;		for (Synset synset1 : indexword1.getSenses()) {			for (Synset synset2 : indexword2.getSenses()) {				double distance = getSubSuperICScore(synset1, synset2);				if (distance < mindistance)					mindistance = distance;			}		}		return mindistance;	}	public boolean isSubSuperConcepts(String label1, String label2)			throws JWNLException {		LabelTokenizer tokenizer = new LabelTokenizer();		List<String> items1 = tokenizer.tokenize(label1);		List<String> items2 = tokenizer.tokenize(label2);		if (items1.size() != items2.size())			return false;		int len = items1.size();		int relation = 0;		for (int i = len - 1; i >= 0; i--) {			String item1 = items1.get(i).toLowerCase();			String item2 = items2.get(i).toLowerCase();			if (relation == 0 && item1.equalsIgnoreCase(item2))				continue;			int curRelation = getSubSuperScore(item1, item2);			if (curRelation == Config.NOT_IS_A())				return false;			if (relation == 0)				relation = curRelation;			else {				if (relation * curRelation > 0)					continue;				if (relation * curRelation <= 0)					return false;			}		}		if (relation != 0)			return true;		return false;	}	public boolean isSubConcepts(List<String> labels1, List<String> lables2) {		return false;	}	/**	 * Initializes the Information Content	 * @param ic_file	 * @throws Exception	 */	public void initializeIC(String ic_file) throws Exception {		if (alreadySetIC)			return;		// a handle to the infocontent file		BufferedReader in = null;		try {			// open the info content file for reading			in = new BufferedReader(new FileReader(ic_file));			// get the first line from the file (should be the WordNet version			// info)			String line = in.readLine();			// Check that what we have is actually a file of IC values			if (line == null || !line.startsWith("wnver::"))				throw new IOException("Malformed InfoContent file");			// Check that the IC file is meant for use with the version			// of WordNet we are currently using			if (!line.endsWith("::" + JWNL.getVersion().getNumber()))				throw new Exception(						"InfoContent file version doesn't match WordNet version");			// Initially set the IC values of the noun and verb roots to 0			freq.put("n", 0d);			freq.put("v", 0d);			// Get the first line of real data ready for use			line = in.readLine();			while (line != null && !line.equals("")) {				// while there is still data in the file to process...				// split the line on the whitespace				String[] data = line.split("\\s+");				// store the frequency (2nd column) against the synset ID (1st				// column)				freq.put(data[0], new Double(data[1]));				if (data.length == 3 && data[2].equals("ROOT")) {					// if there are three columns on this line and the					// last one is ROOT then...					// get the POS tag of the synset					String pos = data[0].substring(data[0].length() - 1);					// updated the node frequency for the POS tag					freq.put(pos, Double.parseDouble(data[1]) + freq.get(pos));				}				// read in the next line from the file ready for processing				line = in.readLine();			}			// setting IC status			alreadySetIC = true;		} finally {			// if we managed to open the file then close it			if (in != null)				in.close();		}	}	/**	 * Generates the key to access the frequency count data loaded from the	 * information content file.	 * 	 * @param synset	 *            the synset for which to generate the key.	 * @return the key to access the frequency count map.	 */	protected String getFreqKey(Synset synset) {		// the keys used by the infomation content files are simply		// the offsets in the dictionary database (minus leading zeros)		// followed by the single character POS tag. So simply build		// a key of this type...		return synset.getOffset() + synset.getPOS().getKey();	}	/**	 * Gets the Information Content (IC) value associated with the given synset.	 * 	 * @param synset	 *            the synset for which to calcualte IC.	 * @return the IC of the given synset.	 */	public float getIC(Synset synset) {		// get the POS tag of this synset		POS pos = synset.getPOS();		// Information Content is only defined for nouns and verbs		// so return 0 if the POS tag is something else		if (!pos.equals(POS.NOUN) && !pos.equals(POS.VERB))			return 0f;		// Get the frequency of this synset from the storred data		Double synFreq = freq.get(getFreqKey(synset));		// if the frequency isn't defined or it's 0 then simlpy return 0		if (synFreq == null || synFreq.doubleValue() == 0)			return 0f;		// Get the frequency of the root node for this POS tage		Double rootFreq = freq.get(synset.getPOS().getKey());		// calcualte the probability for this synset		double prob = synFreq.doubleValue() / rootFreq.doubleValue();		// if the probability is valid then use it to return the IC value		if (prob > 0)			return (float) -Math.log(prob);		// something went wrong so assume IC of 0		return 0f;	}	/**	 * Returns the frequency of the root node of the hierarchy for the given POS	 * tag.	 * 	 * @param pos	 *            the POS tag of the root node to access	 * @return the frequency of the root node for the given POS tag	 */	protected double getFrequency(POS pos) {		return freq.get(pos.getKey());	}	/**	 * Returns the frequency of the given synset.	 * 	 * @param synset	 *            the synset to retrieve the frequency of	 * @return the frequency of the supplied synset	 */	protected double getFrequency(Synset synset) {		Double f = freq.get(getFreqKey(synset));		if (f == null || f.doubleValue() == 0)			return 0;		return f.doubleValue();	}	// //////////////////////////////////////////////////////////////////////////////////////////////	public static void main(String[] args) throws Exception {		try {			WordNetHelper.getInstance().initializeWN(Config.WNDIR(),					Config.WNVER());			WordNetHelper.getInstance().initializeIC(Config.WNIC());		} catch (Exception e) {			// TODO Auto-generated catch block			e.printStackTrace();		}		test1();		test2();		System.out.println("--------------------------------------------");		test3();		System.out.println("--------------------------------------------");		test4();		WordNetHelper.getInstance().uninstall();	}	public static void test1() throws Exception {		// String word = "subject_area";		String[] words = { "Subject", "card credit", "hast running away",				"subject_area", "children abcx", "subject 123 area",				"phd and ms student", "Intestinal_Epithelium",				"Right_Fallopian_Tube", "oviduct uterine_tube", "phd",				"co author" };		for (String word : words) {			System.out.println("Looking for : " + word);			/*			 * for(String item :			 * WordNetHelper.getInstance().getMaxBaseForm(word.toLowerCase(),			 * 3)) { System.out.println("\t" + item); }			 */			System.out.println("----------------------------------");			for (String item : WordNetHelper.getInstance().getAllBaseForm(					word.toLowerCase(), POS.NOUN, 3)) {				System.out.println("\t" + item);			}		}	}	public static void test2() throws Exception {		String[] list1 = { "paper", "Conference", "location", "participant",				"member", "sponsor", "event" };		String[] list2 = { "card", "session", "place", "attendee", "attendee",				"presenter", "activity" };		for (int i = 0; i < list1.length; i++) {			String word1 = list1[i];			String word2 = list2[i];			int distance = WordNetHelper.getInstance().getSubSuperScore(word1,					word2);			if (distance == Config.NOT_IS_A()) {				System.out.println(word1 + ", " + word2						+ " : dont have IS-A relation");				continue;			}			if (distance == 0) {				System.out.println(word1 + ", " + word2 + " : are synonym");				continue;			}			if (distance > 0) {				System.out.println(word1 + " is a hypernym of " + word2						+ " with distance " + distance);				continue;			}			if (distance < 0) {				System.out.println(word1 + " is a hyponym of " + word2						+ " with distance " + distance);				continue;			}		}	}	public static void test3() throws Exception {		String[] list1 = { "paper", "Conference", "location", "participant",				"member", "sponsor", "event" };		String[] list2 = { "card", "session", "place", "attendee", "attendee",				"presenter", "activity" };		for (int i = 0; i < list1.length; i++) {			String word1 = list1[i];			String word2 = list2[i];			double distance = WordNetHelper.getInstance().getSubSuperICScore(					word1, word2);			if (distance == Config.NOT_IS_A()) {				System.out.println(word1 + ", " + word2						+ " : dont have IS-A relation");				continue;			}			if (distance == 1) {				System.out.println(word1 + ", " + word2 + " : are synonym");				continue;			}			System.out.println(word1 + ", " + word2					+ " have IS_A relation with score " + distance);		}	}	public static void test4() throws Exception {		String[] list1 = { "Paper", "Conference", "location", "participant",				"member", "sponsor", "ConferenceChair", "chairman", "paper" };		String[] list2 = { "card", "session", "place", "attendee", "attendee",				"presenter", "Session_Chair", "chair", "contribution" };		for (int i = 0; i < list1.length; i++) {			String word1 = list1[i];			String word2 = list2[i];			boolean isaRel = WordNetHelper.getInstance().isSubSuperConcepts(					word1, word2);			if (isaRel)				System.out						.println(word1 + ", " + word2 + " have IS_A relation");			else				System.out.println(word1 + ", " + word2						+ " DOES NOT have IS_A relation");		}	}}